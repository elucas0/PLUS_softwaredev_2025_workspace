{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4af6a28",
      "metadata": {},
      "source": [
        "# A3 : Model comparison for satellite imagery with TorchGeo\n",
        "\n",
        "This Jupyter Notebook allows you to:\n",
        "- Upload your own satellite imagery\n",
        "- Compare two different pre-trained models side-by-side\n",
        "- Visualize results with detailed performance metrics\n",
        "\n",
        "Built with [TorchGeo](https://github.com/microsoft/torchgeo), to get pre-trained models for satellite imagery.\n",
        "\n",
        "### Disclaimer\n",
        "This notebook is a work in progress. The code is a starting point for your own experiments and may require modifications to work with your specific dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports",
      "metadata": {},
      "source": [
        "## Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This first cell installs the required libraries for the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "14527af3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TorchGeo version: 0.7.0\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from io import BytesIO\n",
        "\n",
        "# TorchGeo imports\n",
        "try:\n",
        "    import torchgeo\n",
        "    print(f\"TorchGeo version: {torchgeo.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Please install torchgeo: pip install torchgeo\")\n",
        "    raise\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config",
      "metadata": {},
      "source": [
        "## Configuration and Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have set up the configuration for the notebook, including the model names. You can change the model names to compare different pre-trained models but make sure they are compatible with your image data.\n",
        "\n",
        "As a starting point, I have included two models: `resnet18` and `resnet50`. You can replace these with any other [models available in TorchGeo](https://torchgeo.readthedocs.io/en/stable/api/models.html#). Make sure to also update the [pre-trained weights](https://torchgeo.readthedocs.io/en/stable/api/models.html#pretrained-weights) if you choose different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "config_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Available pre-trained models for comparison\n",
        "available_models = {\n",
        "    'ResNet-18': 'resnet18',\n",
        "    'ResNet-50': 'resnet50',\n",
        "}\n",
        "\n",
        "available_sensors = {\n",
        "    'Sentinel-2' : 'sentinel2'\n",
        "}\n",
        "\n",
        "loaded_models = {}\n",
        "image = None\n",
        "image_tensor = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_models(output_area, selected_models):\n",
        "    \"\"\"Load selected models\n",
        "\n",
        "    Args:\n",
        "        output_area (widgets.Output): Output area for displaying messages\n",
        "        selected_models (list): List of selected model names\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of loaded models\n",
        "    \"\"\"\n",
        "    global loaded_models\n",
        "        \n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "        print(\"Loading models...\")\n",
        "                        \n",
        "        loaded_models = {}\n",
        "            \n",
        "        for model_name in selected_models:\n",
        "            try:\n",
        "                print(f\"Loading {model_name}...\")\n",
        "                    \n",
        "                # Get model architecture\n",
        "                arch_name = available_models[model_name]\n",
        "                    \n",
        "                # Try to load with pretrained weights\n",
        "                if 'resnet' in arch_name:\n",
        "                    from torchgeo.models import resnet18, resnet50\n",
        "                    from torchgeo.models import ResNet18_Weights,  ResNet50_Weights\n",
        "                    if arch_name == 'resnet18':\n",
        "                        weights = ResNet18_Weights.SENTINEL2_RGB_MOCO\n",
        "                        model = resnet18(weights)\n",
        "                    else :\n",
        "                        weights = ResNet50_Weights.SENTINEL2_RGB_MOCO\n",
        "                        model = resnet50(weights)\n",
        "                else:\n",
        "                    print(f\"Model {model_name} not implemented, skipping...\")\n",
        "                    continue\n",
        "                    \n",
        "                model.eval()\n",
        "                model.to(device)\n",
        "                loaded_models[model_name] = model\n",
        "                print(f\"{model_name} loaded successfully\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {model_name}: {str(e)}\")\n",
        "            \n",
        "        if loaded_models:\n",
        "            print(f\"Successfully loaded {len(loaded_models)}\")\n",
        "            loaded_models = loaded_models\n",
        "            return loaded_models\n",
        "        else:\n",
        "            print(\"No models loaded successfully\")\n",
        "            return {}            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-processing\n",
        "A function to preprocess the uploaded image is defined. This function resizes the image to the input size required by the model and normalizes it using the mean and standard deviation values specific to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    \"\"\"Preprocess image for model inference\n",
        "\n",
        "    Args:\n",
        "        image (PIL.Image): The image to preprocess\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The preprocessed image tensor\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return\n",
        "        \n",
        "    # Standard ImageNet preprocessing\n",
        "    transform = Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "        \n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "    \n",
        "def display_image(image, title=\"Current Image for Inference\"):\n",
        "    \"\"\"Display an image\n",
        "\n",
        "    Args:\n",
        "        image (PIL.Image): The image to display\n",
        "        title (str, optional): Title for the displayed image. Defaults to \"Current Image for Inference\".\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "            \n",
        "def handle_uploaded_image(uploaded_file, output_area):\n",
        "    \"\"\"Handle upload of a custom image\n",
        "\n",
        "    Args:\n",
        "        uploaded_file (dict): The uploaded file information\n",
        "        output_area (widgets.Output): Output area for displaying messages\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the image was processed successfully, False otherwise\n",
        "    \"\"\"\n",
        "    global current_image, image_tensor\n",
        "    \n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "        print(\"Processing uploaded image...\")\n",
        "        \n",
        "        try:\n",
        "            # Process the uploaded file\n",
        "            image = Image.open(BytesIO(uploaded_file['content'])).convert('RGB')\n",
        "            current_image = image\n",
        "            image_tensor = preprocess_image(image)\n",
        "            display_image(image)\n",
        "            print(\"Image uploaded and processed successfully!\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing uploaded image: {str(e)}\")\n",
        "            return False\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_inference(loaded_models, image_tensor, results_area):\n",
        "    \"\"\"Run inference on all loaded models\n",
        "\n",
        "    Args:\n",
        "        loaded_models (dict): Dictionary of loaded models\n",
        "        image_tensor (torch.Tensor): Preprocessed image tensor\n",
        "        results_area (widgets.Output): Output area for displaying results\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing the inference results\n",
        "    \"\"\"\n",
        "    if not loaded_models or image_tensor is None:\n",
        "        with results_area:\n",
        "            print(\"Please load models and an image first!\")\n",
        "        return None\n",
        "    \n",
        "    with results_area:\n",
        "        clear_output(wait=True)\n",
        "        print(\"Running inference on selected models...\")\n",
        "        \n",
        "        results = {}\n",
        "        \n",
        "        # Run inference on each model\n",
        "        with torch.no_grad():\n",
        "            for model_name, model in loaded_models.items():\n",
        "                try:\n",
        "                    print(f\"Running {model_name}...\")\n",
        "                    \n",
        "                    # Forward pass\n",
        "                    outputs = model(image_tensor)\n",
        "                    \n",
        "                    # Get probabilities\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    top_probs, top_indices = torch.topk(probabilities, 5)\n",
        "                    \n",
        "                    results[model_name] = {\n",
        "                        'probabilities': top_probs.cpu().numpy()[0],\n",
        "                        'indices': top_indices.cpu().numpy()[0],\n",
        "                        'raw_outputs': outputs.cpu().numpy()[0]\n",
        "                    }\n",
        "                    \n",
        "                    print(f\"{model_name} completed\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Error with {model_name}: {str(e)}\")\n",
        "                    results[model_name] = None\n",
        "                    \n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_results(results):\n",
        "    \"\"\"Display inference results comparison\n",
        "\n",
        "    Args:\n",
        "        results (dict): Dictionnary containing the results\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"Inference results comparison\")\n",
        "        \n",
        "        # Create comparison visualization\n",
        "    valid_results = {k: v for k, v in results.items() if v is not None}\n",
        "        \n",
        "    if not valid_results:\n",
        "        print(\"No valid results to display\")\n",
        "        return\n",
        "        \n",
        "    # Plot comparison\n",
        "    fig, axes = plt.subplots(2, len(valid_results), figsize=(5*len(valid_results), 10))\n",
        "    if len(valid_results) == 1:\n",
        "        axes = axes.reshape(2, 1)\n",
        "        \n",
        "    # Load ImageNet class names (simplified version)\n",
        "    imagenet_classes = [f\"Class_{i}\" for i in range(1000)]  # Simplified\n",
        "        \n",
        "    for idx, (model_name, result) in enumerate(valid_results.items()):\n",
        "            # Top predictions bar chart\n",
        "        ax1 = axes[0, idx] if len(valid_results) > 1 else axes[0]\n",
        "        top_probs = result['probabilities']\n",
        "        top_indices = result['indices']\n",
        "            \n",
        "        class_names = [f\"Class {i}\" for i in top_indices]\n",
        "            \n",
        "        bars = ax1.bar(range(5), top_probs, color=plt.cm.viridis(np.linspace(0, 1, 5)))\n",
        "        ax1.set_xlabel('Top 5 Classes')\n",
        "        ax1.set_ylabel('Probability')\n",
        "        ax1.set_title(f'{model_name}\\nTop 5 Predictions')\n",
        "        ax1.set_xticks(range(5))\n",
        "        ax1.set_xticklabels([f\"C{i}\" for i in top_indices], rotation=45)\n",
        "            \n",
        "        # Add probability values on bars\n",
        "        for bar, prob in zip(bars, top_probs):\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{prob:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "            \n",
        "        # Raw output distribution\n",
        "        ax2 = axes[1, idx] if len(valid_results) > 1 else axes[1]\n",
        "        raw_outputs = result['raw_outputs']\n",
        "            \n",
        "        # Show distribution of raw outputs (sample first 100 for clarity)\n",
        "        sample_outputs = raw_outputs[:100] if len(raw_outputs) > 100 else raw_outputs\n",
        "        ax2.hist(sample_outputs, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        ax2.set_xlabel('Raw Output Value')\n",
        "        ax2.set_ylabel('Frequency')\n",
        "        ax2.set_title(f'{model_name}\\nRaw Output Distribution')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print detailed results\n",
        "        print(\"\\n📊 DETAILED RESULTS:\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        for model_name, result in valid_results.items():\n",
        "            print(f\"\\n {model_name}:\")\n",
        "            print(f\"   Top prediction: Class {result['indices'][0]} ({result['probabilities'][0]:.4f})\")\n",
        "            print(f\"   Confidence: {result['probabilities'][0]:.1%}\")\n",
        "            print(f\"   Top 3 classes: {', '.join([f'Class {i}' for i in result['indices'][:3]])}\")\n",
        "            \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ui_section",
      "metadata": {},
      "source": [
        "## Interactive Model and Dataset Selection\n",
        "\n",
        "This section allows you to select the model and dataset interactively. You can upload your own image for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create widgets\n",
        "def create_interface():\n",
        "    \"\"\"Create and return the interactive interface widgets\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the interface widgets\n",
        "    \"\"\"\n",
        "    \n",
        "    # Model selection dropdown\n",
        "    model_selector_1 = widgets.Dropdown(\n",
        "        options=list(available_models.keys()),\n",
        "        value='ResNet-18',\n",
        "        description='Select model 1:',\n",
        "        disabled=False,\n",
        "    )\n",
        "    \n",
        "    model_selector_2 = widgets.Dropdown(\n",
        "        options=list(available_models.keys()),\n",
        "        value='ResNet-50',\n",
        "        description='Select model 2 :',\n",
        "        disabled=False,\n",
        "    )\n",
        "    \n",
        "    # Image upload widget\n",
        "    image_uploader = widgets.FileUpload(\n",
        "        accept='image/*',\n",
        "        multiple=False,\n",
        "        description='Upload Image'\n",
        "    )\n",
        "    \n",
        "    # Sensor selector\n",
        "    sensor_selector = widgets.Dropdown(\n",
        "        options=list(available_sensors.keys()),\n",
        "        value='Sentinel-2',\n",
        "    )\n",
        "    \n",
        "    # Buttons\n",
        "    load_models_btn = widgets.Button(\n",
        "        description='Load Selected Models',\n",
        "        button_style='primary',\n",
        "        icon='download'\n",
        "    )\n",
        "    \n",
        "    run_inference_btn = widgets.Button(\n",
        "        description='Run Inference',\n",
        "        button_style='success',\n",
        "        icon='play',\n",
        "        disabled=True\n",
        "    )\n",
        "    \n",
        "    # Output areas\n",
        "    output_area = widgets.Output()\n",
        "    results_area = widgets.Output()\n",
        "    \n",
        "    # Event handlers\n",
        "    def on_load_models_click(button):\n",
        "        selected_models = [model_selector_1.value, model_selector_2.value]\n",
        "        load_models(output_area, selected_models)\n",
        "        if loaded_models:\n",
        "            run_inference_btn.disabled = False if image_tensor is not None else True\n",
        "    \n",
        "    def on_run_inference_click(button):\n",
        "        results = run_inference(loaded_models, image_tensor, results_area)\n",
        "        display_results(results)\n",
        "    \n",
        "    def on_upload_change(change):\n",
        "        if change['new']:\n",
        "            uploaded_file = list(change['new'])[0]\n",
        "            success = handle_uploaded_image(uploaded_file, output_area)\n",
        "            if success and loaded_models:\n",
        "                run_inference_btn.disabled = False\n",
        "    \n",
        "    # Attach event handlers\n",
        "    load_models_btn.on_click(on_load_models_click)\n",
        "    run_inference_btn.on_click(on_run_inference_click)\n",
        "    image_uploader.observe(on_upload_change, names='value')\n",
        "    \n",
        "    return {\n",
        "        'model_selector_1': model_selector_1,\n",
        "        'model_selector_2': model_selector_2,\n",
        "        'image_uploader': image_uploader,\n",
        "        'load_models_btn': load_models_btn,\n",
        "        'sensor_selector' : sensor_selector,\n",
        "        'run_inference_btn': run_inference_btn,\n",
        "        'output_area': output_area,\n",
        "        'results_area': results_area\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08e6734d256b4257a0a613de5380bb56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(VBox(children=(HTML(value='<h3>1. Select Models to Compare</h3>'), Dropdown(description='Select…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create and display the interface\n",
        "def display_interface():\n",
        "    \"\"\"Create and display the interactive interface for model comparison\n",
        "    \"\"\"\n",
        "    widgets_dict = create_interface()\n",
        "    \n",
        "    # Layout the interface\n",
        "    model_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>1. Select Models to Compare</h3>\"),\n",
        "        widgets_dict['model_selector_1'],\n",
        "        widgets_dict['model_selector_2'],\n",
        "        widgets_dict['load_models_btn']\n",
        "    ])\n",
        "    \n",
        "    image_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>2. Choose Image Source</h3>\"),\n",
        "        widgets.HTML(\"<b>Upload your own image</b>\"),\n",
        "        widgets_dict['image_uploader'],\n",
        "        widgets.HTML(\"<b>Select source sensor</b>\"),\n",
        "        widgets_dict['sensor_selector']\n",
        "    ])\n",
        "    \n",
        "    inference_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>3. Run Inference</h3>\"),\n",
        "        widgets_dict['run_inference_btn']\n",
        "    ])\n",
        "    \n",
        "    interface = widgets.VBox([\n",
        "        model_box,\n",
        "        widgets.HTML(\"<hr>\"),\n",
        "        image_box, \n",
        "        widgets.HTML(\"<hr>\"),\n",
        "        inference_box,\n",
        "        widgets.HTML(\"<hr>\"),\n",
        "        widgets.HTML(\"<h3>Output</h3>\"),\n",
        "        widgets_dict['output_area'],\n",
        "        widgets_dict['results_area']\n",
        "    ])\n",
        "    \n",
        "    display(interface)\n",
        "\n",
        "# Initialize and display the interface\n",
        "display_interface()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torchgeo_model_comparison",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
